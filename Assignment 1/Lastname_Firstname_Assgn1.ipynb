{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32c4985c",
      "metadata": {
        "id": "32c4985c"
      },
      "source": [
        "# ECE1508: Applied Deep Learning\n",
        "# Assignment 1\n",
        "## Lastname, Firstname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9bf05ff1",
      "metadata": {
        "id": "9bf05ff1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22af6c21",
      "metadata": {},
      "source": [
        "Try an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RkhJIFJJoMEq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkhJIFJJoMEq",
        "outputId": "66b8f0f3-d4a6-4d5d-815a-275443436212"
      },
      "outputs": [],
      "source": [
        "np.ones(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "772fbb27",
      "metadata": {
        "id": "772fbb27"
      },
      "source": [
        "## Programming Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3f57c2fe",
      "metadata": {
        "id": "3f57c2fe"
      },
      "outputs": [],
      "source": [
        "class LinearMachine():\n",
        "    def __init__(self):\n",
        "        # Define weights as attribute\n",
        "        # Set the initial values randomly\n",
        "\n",
        "        # ============ COMPLETE HERE ================\n",
        "        # self._weights = ## COMPLETE ##\n",
        "        # ============================================\n",
        "        pass\n",
        "\n",
        "    def data_synthesizer(self, dataset_size, velocity_mean, velocity_var,\n",
        "                         height_mean, height_var):\n",
        "\n",
        "        # Draw random velocity and height\n",
        "        # Let the array size to be <dataset_size>\n",
        "        # Don't forget to make them positive using np.abs()\n",
        "        \n",
        "        # ============ COMPLETE HERE ================\n",
        "        # v_sample = ## COMPLETE ##\n",
        "        # h_sample = ## COMPLETE ##\n",
        "\n",
        "        # Compute distance d via Newton's law\n",
        "        # d_sample = ## COMPLETE ##\n",
        "        # ============================================\n",
        "\n",
        "        # Make the dataset\n",
        "        # ============ COMPLETE HERE ================\n",
        "        # dataset = ## COMPLETE ##\n",
        "        # return dataset\n",
        "        # ============================================\n",
        "        pass\n",
        "\n",
        "    def train_GD(self, dataset, lr, delta = float(\"inf\"), max_iterations = 1e12):\n",
        "\n",
        "        # We can reset the weights to some initial random values\n",
        "        # ============ COMPLETE HERE ================\n",
        "        # self._weights = ## COMPLETE ##\n",
        "        # ============================================\n",
        "\n",
        "        # read data-points and labels\n",
        "        # ============ COMPLETE HERE ================\n",
        "        # x_mat = ## COMPLETE ##\n",
        "        # d_mat = ## COMPLETE ##\n",
        "        # ============================================\n",
        "\n",
        "        # Count number of iterations to stop after max iterations\n",
        "        counter = 0\n",
        "\n",
        "        # Initiate risk\n",
        "        risk = 0\n",
        "\n",
        "        while delta > 0 and counter < max_iterations:\n",
        "            \n",
        "            # Compute Gradient\n",
        "            # ============ COMPLETE HERE ================\n",
        "            # grad = ## COMPLETE ## Multiple lines\n",
        "            # ============================================\n",
        "\n",
        "            # Save risk at current weights\n",
        "            # ============ COMPLETE HERE ================\n",
        "            old_risk = 0 ## COMPLETE ##\n",
        "            # ============================================\n",
        "\n",
        "            # Update weights using GD with learning rate lr\n",
        "            # ============ COMPLETE HERE ================\n",
        "            # self._weights = ## COMPLETE ##\n",
        "            # ============================================\n",
        "\n",
        "            # Compute new risk\n",
        "            # ============ COMPLETE HERE ================\n",
        "            # risk = ## COMPLETE ## Multiple lines\n",
        "            # ============================================\n",
        "\n",
        "            # Update stopping criteria\n",
        "            delta = np.abs(risk - old_risk)\n",
        "            counter += 1\n",
        "\n",
        "        # Print out if the code stops due to max iterations, i.e., GD did not converge\n",
        "        if counter == max_iterations:\n",
        "            print(f\"GD dos not converge: train_GD hit max iterations = {max_iterations}!\")\n",
        "\n",
        "        return risk\n",
        "    \n",
        "\n",
        "    def train(self, dataset):\n",
        "          # Find the minimizer\n",
        "          # ============ COMPLETE HERE ================\n",
        "          # self._weights = ## COMPLETE ## Multiple lines\n",
        "          # ============================================\n",
        "\n",
        "\n",
        "          # Compute minimum risk\n",
        "          # ============ COMPLETE HERE ================\n",
        "          risk_opt = 0  ## COMPLETE ## Multiple lines\n",
        "          # ============================================\n",
        "          return risk_opt\n",
        "\n",
        "    def test(self, J, velocity_mean, velocity_var, height_mean, height_var):\n",
        "          \n",
        "          # Generate an independent dataset for test\n",
        "          # ============ COMPLETE HERE ================\n",
        "          dataset = [] ## COMPLETE ##\n",
        "          # ============================================\n",
        "\n",
        "          # Compute the risk via the trained weights\n",
        "          # ============ COMPLETE HERE ================\n",
        "          # ## COMPLETE ## Multiple lines\n",
        "          # ============================================\n",
        "\n",
        "          # Compute test risk\n",
        "          # ============ COMPLETE HERE ================\n",
        "          risk_test = 0  ## COMPLETE ##\n",
        "          # ============================================\n",
        "          return risk_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167b2f11",
      "metadata": {
        "id": "167b2f11"
      },
      "source": [
        "### Gradient Descent vs Optimal Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c20609b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "4c20609b",
        "outputId": "490a987e-d25e-418e-bb5f-82dee1e9ef9f"
      },
      "outputs": [],
      "source": [
        "def Optimality_Gap(lr_list):\n",
        "    myModel = LinearMachine()\n",
        "    dataset = myModel.data_synthesizer(100, 1, 5, 3, 3)\n",
        "\n",
        "    # Initiate optimality gap vector\n",
        "    Opt_gap = []\n",
        "\n",
        "    # Find optimal weights\n",
        "    myModel.train(dataset)\n",
        "    weights_optimal = myModel._weights\n",
        "\n",
        "    # Find GD trained weights \n",
        "    for lr in lr_list:\n",
        "        # ============ COMPLETE HERE ================\n",
        "        weights_GD = 0 ## COMPLETE ## Multiple lines\n",
        "        # ============================================\n",
        "\n",
        "        # Append the optimality gap \n",
        "        Opt_gap.append(np.linalg.norm(weights_optimal-weights_GD))\n",
        "\n",
        "\n",
        "    # Plot \n",
        "    plt.figure()\n",
        "    plt.plot(lr_list, Opt_gap)\n",
        "    plt.title('GD vs Optimal Training')\n",
        "    plt.xlabel('Learning Rate')\n",
        "    plt.ylabel('Distance between Optimal and GD Weights')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Execute your implementation\n",
        "Optimality_Gap([0.1, 0.01, 0.001, 0.0001])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0lh_ebARkgh",
      "metadata": {
        "id": "e0lh_ebARkgh"
      },
      "source": [
        "### Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qdwz_VkRRnDB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "qdwz_VkRRnDB",
        "outputId": "9f73b61c-3894-43fd-ab00-a66f534e8c01"
      },
      "outputs": [],
      "source": [
        "def eval_model(T, I, J, velocity_mean, velocity_var, height_mean, height_var):\n",
        "  myModel = LinearMachine()\n",
        "  lr = 0.001\n",
        "  \n",
        "  # Initiate the risk \n",
        "  emp_risk = 0\n",
        "\n",
        "  # Loop over t\n",
        "  for t in range(T):\n",
        "    # ============ COMPLETE HERE ================\n",
        "    emp_risk = 0 # # ## COMPLETE ## Multiple lines\n",
        "    # # ============================================\n",
        "  \n",
        "  # average rist over datasets\n",
        "  emp_risk = emp_risk / T\n",
        "\n",
        "  return emp_risk\n",
        "\n",
        "\n",
        "# Make list for plot\n",
        "emp_risk_list = []\n",
        "T, J = 100, 10\n",
        "\n",
        "# loop over I\n",
        "I_list = [10*i for i in range(1,21)]\n",
        "for I in I_list:\n",
        "  emp_risk_list.append(eval_model(T, I, J, 1, 5, 3, 3))\n",
        "\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "plt.plot(I_list, emp_risk_list)\n",
        "plt.title('Test Risk against Size of Dataset')\n",
        "plt.xlabel('Dataset Size')\n",
        "plt.ylabel('Test Risk')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3efab1b",
      "metadata": {
        "id": "c3efab1b"
      },
      "source": [
        "## Programming Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e76703be",
      "metadata": {
        "id": "e76703be"
      },
      "source": [
        "### Perceptron Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "30a5009f",
      "metadata": {
        "id": "30a5009f"
      },
      "outputs": [],
      "source": [
        "class PerceptronMachine():\n",
        "    def __init__(self):\n",
        "        # define weights as attribute and initiate randomly\n",
        "        self._dimensions = 9\n",
        "        # ============ COMPLETE HERE ================\n",
        "        # ## COMPLETE ## Multiple lines\n",
        "        # ============================================\n",
        "\n",
        "\n",
        "    def forward(self, datapoint):\n",
        "        # Affine function\n",
        "        # ============ COMPLETE HERE ================\n",
        "        # ## COMPLETE ## Multiple lines\n",
        "        # ============================================\n",
        "\n",
        "        # Activate by step function\n",
        "        return 1 if affine > 0 else 0\n",
        "\n",
        "    def train(self, dataset, lr):\n",
        "        # initiate weights again randomly as we start with training\n",
        "        # ============ COMPLETE HERE ================\n",
        "        # ## COMPLETE ## Multiple lines\n",
        "        # ============================================\n",
        "\n",
        "        # initiate error_flag with 1 to get to the while loop\n",
        "        error_flag = 1\n",
        "\n",
        "        while error_flag > 0:\n",
        "            # We initially have no error\n",
        "            error_flag = 0\n",
        "            for data in dataset:\n",
        "                # Read data\n",
        "                x = data[0]\n",
        "                label = data[1]\n",
        "\n",
        "                # Pass it forward\n",
        "                y = self.forward(x)\n",
        "\n",
        "                # Implement inner loop\n",
        "                if y != label:\n",
        "                    # Find sign(z) \n",
        "                    # ============ COMPLETE HERE ================\n",
        "                    # ## COMPLETE ## \n",
        "                    # ============================================\n",
        "\n",
        "                    # Set movement vector = sgn(z) * x\n",
        "                    # ============ COMPLETE HERE ================\n",
        "                    # ## COMPLETE ## \n",
        "                    # ============================================\n",
        "\n",
        "                    # Update\n",
        "                    # ============ COMPLETE HERE ================\n",
        "                    # ## COMPLETE ## \n",
        "                    # ============================================\n",
        "\n",
        "                    # Since we had error, we set the flag 1 again\n",
        "                    error_flag = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759b165c",
      "metadata": {
        "id": "759b165c"
      },
      "source": [
        "### X Pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de8b748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "4de8b748",
        "outputId": "1bc3752a-6eac-4863-9e31-f944c10a31f3"
      },
      "outputs": [],
      "source": [
        "# Generating the X Pattern\n",
        "# Run this code to see X pattern\n",
        "\n",
        "x = 256* np.ones([3,3],dtype = int)\n",
        "\n",
        "for i in range(3):\n",
        "    x[i,i] = 0\n",
        "    x[i,2-i] = 0\n",
        "\n",
        "plt.imshow(x,cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5735b70c",
      "metadata": {},
      "source": [
        "### Generate Dataset and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e456c8c4",
      "metadata": {
        "id": "e456c8c4"
      },
      "outputs": [],
      "source": [
        "# Generate the Dataset\n",
        "# Initiate empty dataset\n",
        "dataset = []\n",
        "image_list = []\n",
        "\n",
        "# We have 2^9=512 possibilities: loop over them\n",
        "for i in range(512): \n",
        "    # generate 9-dimensional vector\n",
        "    # ============ COMPLETE HERE ================\n",
        "    # ## COMPLETE ## Multiple lines\n",
        "    # ============================================\n",
        "\n",
        "    # label the vector\n",
        "    # ============ COMPLETE HERE ================\n",
        "    # ## COMPLETE ## Multiple lines\n",
        "    # ============================================\n",
        "\n",
        "\n",
        "# Instantiate a perceptron and train it \n",
        "myModel = PerceptronMachine()\n",
        "myModel.train(dataset, 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd37a12a",
      "metadata": {},
      "source": [
        "### Test Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8AtYTuy6x0IU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AtYTuy6x0IU",
        "outputId": "075a7fea-ec6f-4e16-b38e-0b2a62d71b37"
      },
      "outputs": [],
      "source": [
        "# Initiate the test set\n",
        "testset = []\n",
        "\n",
        "# Add the X pattern\n",
        "testset.append([0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "# Choose some data samples\n",
        "for i in range(10):\n",
        "    rand_idx = int(np.random.rand() * 512) % 512\n",
        "    while rand_idx == 170:\n",
        "        rand_idx = int(np.random.rand() * 512) % 512\n",
        "    testset.append(dataset[rand_idx][0])\n",
        "\n",
        "\n",
        "# Test the set: only the first one should return 1\n",
        "for test in testset:\n",
        "    print(f\"Is it X patter? Answer: {myModel.forward(test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a842236",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
